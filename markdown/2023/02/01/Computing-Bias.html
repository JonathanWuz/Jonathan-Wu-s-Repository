<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Big Idea 5.3 Computing Bias | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Big Idea 5.3 Computing Bias" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on Bias in Computing" />
<meta property="og:description" content="Notes on Bias in Computing" />
<link rel="canonical" href="https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/markdown/2023/02/01/Computing-Bias.html" />
<meta property="og:url" content="https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/markdown/2023/02/01/Computing-Bias.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-01T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Big Idea 5.3 Computing Bias" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-02-01T00:00:00-06:00","datePublished":"2023-02-01T00:00:00-06:00","description":"Notes on Bias in Computing","headline":"Big Idea 5.3 Computing Bias","mainEntityOfPage":{"@type":"WebPage","@id":"https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/markdown/2023/02/01/Computing-Bias.html"},"url":"https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/markdown/2023/02/01/Computing-Bias.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Jonathan-Wu-s-Repository/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/Jonathan-Wu-s-Repository/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Jonathan-Wu-s-Repository/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Jonathan-Wu-s-Repository/about/">About Me</a><a class="page-link" href="/Jonathan-Wu-s-Repository/search/">Search</a><a class="page-link" href="/Jonathan-Wu-s-Repository/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Big Idea 5.3 Computing Bias</h1><p class="page-description">Notes on Bias in Computing</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-02-01T00:00:00-06:00" itemprop="datePublished">
        Feb 1, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Jonathan-Wu-s-Repository/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#computer-bias">Computer Bias</a>
<ul>
<li class="toc-entry toc-h2"><a href="#intentional-or-purposeful-bias-crossover-group-up-10-minutes">Intentional or Purposeful bias (Crossover Group Up, 10 minutes)</a></li>
<li class="toc-entry toc-h2"><a href="#as-pairs-5-minutes">As Pairs (5 minutes)</a></li>
<li class="toc-entry toc-h2"><a href="#hacks">Hacks</a></li>
</ul>
</li>
</ul><h1 id="computer-bias">
<a class="anchor" href="#computer-bias" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computer Bias</h1>

<p>Earlier we talked about beneficial and harmful effects of computing. Such conversation often lead to conversations on computer bias, particularly when bias creates a harmful effect.</p>

<p>As programmers, you now have the possibility of creating algorithms. It has been said, “Humans are error-prone and biased”. So, does that mean algorithms and the computers they run on are better?</p>

<h2 id="intentional-or-purposeful-bias-crossover-group-up-10-minutes">
<a class="anchor" href="#intentional-or-purposeful-bias-crossover-group-up-10-minutes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Intentional or Purposeful bias (Crossover Group Up, 10 minutes)</h2>
<ul>
  <li>Google “What age groups use Facebook” vs “… TikTok”? What does the data say? Is there purposeful exclusion in these platforms?</li>
  <li>Is it harmful? Should it be corrected? Is it good business?</li>
  <li>Why do virtual assistants have female voices? Amazon, Alexa Google, Apple Siri. Was this purposeful? Is it harmful? Should it be corrected? Is it good business?</li>
  <li>Talk about an algorithm that influences your decisions, think about these companies (ie FAANG - Facebook, Amazon, Apple,Netflix, Google)
    <ul>
      <li>The age groups for Facebook and TikTok are likely very different. Facebook likely has a older age group of around 18 or older such as adults whereas TikTok will have a younger age group of around 18 or less. Each group targets a different select audience: Facebook targets adults/ young adults and TikTok targets children/teenagers. I wouldn’t say there is any purposeful exclusion because you can still find teenagers on Facebook and adults on TikTok. However, this exclusion may be harmful since it causes a platform divide between generations. Different age generations will like different things and cause a divide between people. It should be stopped but its good for businesses since it allows them to target certain audiences.</li>
      <li>Virtual Assistants may use female voices because it is often viewed as more welcoming and helpful than a mans voice. This is likely purposeful because it might give the customer a better impression of their product. However, using female voices in assistant services is very problematic because it causes a bias around women and men. It generates a bias that women are generally assistants which is not tru. It also creates a bias that men can not speak interestingly. These are both bad biases that although may be helpful to businesses, are harmful to gender roles.</li>
      <li>Amazon or Google might use algorithms that suggest products to you or sell your information to companies. However, some may view this as a breach of privacy. I, personally, don’t appreciate search engines selling my information. Similarly to before, Businesses benefit from this, selling and advertising things the user will want. Some may argue this algorithm is helpful because it suggests products that the user will want, personalizing a person’s advertisements.</li>
    </ul>
  </li>
</ul>

<h2 id="as-pairs-5-minutes">
<a class="anchor" href="#as-pairs-5-minutes" aria-hidden="true"><span class="octicon octicon-link"></span></a>As Pairs (5 minutes)</h2>
<ul>
  <li>Watch the video… HP computers are racist</li>
  <li>Come up with some thoughts on the video and be ready to discuss them as I call on you. Here are some ideas…</li>
  <li>Does the owner of the computer think this was intentional?
    <ul>
      <li>If yes or no, justify you conclusion.</li>
      <li>How do you think this happened?</li>
      <li>Is this harmful? Was it intended to be harmful or exclude?</li>
      <li>Should it be corrected?</li>
      <li>What would you or should you do to produce a better outcome?</li>
    </ul>
  </li>
  <li>The owner of the video does not think this is intentional because it doesn’t looks like he’s mad and it looks like he’s joking. However, he does mention that HP computers are racist explicitly so it’s hard to tell.</li>
  <li>I think this happened because the lighting makes the guy’s facial features dim down, harder to tell. Thus, it’s possible that the Hp computer didn’t pick up on the guys face and thus, wasn’t able to track it.</li>
  <li>The HP computer is harmful because it doesn’t allow certain people to use their face tracking feature. However, it wasn’t intended to be harmful. HP is a large company and will likely get in a lot of trouble for purposeful exclusion. It was likely just a weak camera tracking system.</li>
  <li>This camera feature should be tried to be fixed. Fixing the feature would allow all people to use it which is ideal. However, it should be noted that troubleshooting takes time.</li>
  <li>I should be aware of computing bias and think about if there are any problems with my program that benefit us but harm the user like with the examples of Google and Amazon. I should also consider people’s backgrounds: age, ethnicity, religion, etc. and make sure no one is excluded from our features.</li>
</ul>

<h2 id="hacks">
<a class="anchor" href="#hacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hacks</h2>
<p>In this world, there are many baises in computer programs, companies, and apps. It is important to take note of these biases and try to void them as much as possible. One bias could be age and how different apps such as Facebook and TikTok have different targeted age groups. On is adult while the other targets teenagers. However, diversity in these types of apps is very important because it leads to less seperation. Another bias can be caused by race, ethnicity, etc. such as with the example of HP’s computer face tracking. In our own program regarding helping companies with shipment, one bias we may need to consider is small vs big businesses. We should help all businesses alike and thus we should be aware of possible biases in our features/ program.</p>


  </div><a class="u-url" href="/Jonathan-Wu-s-Repository/markdown/2023/02/01/Computing-Bias.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Jonathan-Wu-s-Repository/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://jonathanwuz.github.io/Jonathan-Wu-s-Repository/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Jonathan-Wu-s-Repository/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
